{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     x.initializer.run()\n",
    "#     tf.get_default_session().run(x.initializer)\n",
    "#     sess.run(x.initializer)\n",
    "    \n",
    "#     y.initializer.run()\n",
    "#     tf.get_default_session().run(y.initializer)\n",
    "#     sess.run(y.initializer)\n",
    "\n",
    "    init.run()\n",
    "    \n",
    "    result = sess.run(f)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intertactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables are automatically added to default graph\n",
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define graph by yourselves\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "# graph is no longer default graph because it is out of the block\n",
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifecycle of a Node Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n",
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval()) # 10\n",
    "    # For this evaluation, it calculates x & y again.\n",
    "    print(z.eval()) # 15\n",
    "    \n",
    "    # To avoid redundant calculation:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_equation_model():    \n",
    "    X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "    y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "    XT = tf.transpose(X)\n",
    "    theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.74651413e+01]\n",
      " [  4.35734153e-01]\n",
      " [  9.33829229e-03]\n",
      " [ -1.06622010e-01]\n",
      " [  6.44106984e-01]\n",
      " [ -4.25131839e-06]\n",
      " [ -3.77322501e-03]\n",
      " [ -4.26648885e-01]\n",
      " [ -4.40514028e-01]]\n"
     ]
    }
   ],
   "source": [
    "theta = normal_equation_model()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data_plus_bias = scaler.fit_transform(housing_data_plus_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_model():\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "    y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "    theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "\n",
    "    y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "    # 1. Manually calculated gradients\n",
    "    # gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "    # training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "    # 2. Automatically calculated gradients by TensorFlow\n",
    "    # gradients = tf.gradients(mse, [theta])[0]\n",
    "    # training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "    # 3. Using optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(mse)\n",
    "    \n",
    "    return theta, mse, training_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  7.23475\n",
      "Epoch 100 MSE =  4.86437\n",
      "Epoch 200 MSE =  4.83649\n",
      "Epoch 300 MSE =  4.82686\n",
      "Epoch 400 MSE =  4.82034\n",
      "Epoch 500 MSE =  4.81565\n",
      "Epoch 600 MSE =  4.81226\n",
      "Epoch 700 MSE =  4.8098\n",
      "Epoch 800 MSE =  4.80802\n",
      "Epoch 900 MSE =  4.80673\n",
      "[[ 0.62484741]\n",
      " [ 0.81808275]\n",
      " [ 0.1355291 ]\n",
      " [-0.20830411]\n",
      " [ 0.24279805]\n",
      " [ 0.00174982]\n",
      " [-0.04049946]\n",
      " [-0.78841257]\n",
      " [-0.75601125]]\n"
     ]
    }
   ],
   "source": [
    "theta, mse, training_op = gradient_model()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE = \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Mini-Batch & Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mini_batch_gradient_model():\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "    theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "\n",
    "    y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(mse)\n",
    "    \n",
    "    return X, y, theta, mse, training_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(batch_index, batch_size):\n",
    "    startIdx = batch_index * batch_size\n",
    "    endIdx = startIdx + batch_size\n",
    "    return (scaled_housing_data_plus_bias[startIdx:endIdx],\n",
    "            housing.target.reshape(-1, 1)[startIdx:endIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  0.222841\n",
      "Epoch 100 MSE =  0.453871\n",
      "Epoch 200 MSE =  0.453871\n",
      "Epoch 300 MSE =  0.453871\n",
      "Epoch 400 MSE =  0.453871\n",
      "Epoch 500 MSE =  0.453871\n",
      "Epoch 600 MSE =  0.453871\n",
      "Epoch 700 MSE =  0.453871\n",
      "Epoch 800 MSE =  0.453871\n",
      "Epoch 900 MSE =  0.453871\n",
      "[[ -5.29047012e-01]\n",
      " [  9.95532930e-01]\n",
      " [  9.72431973e-02]\n",
      " [ -3.68002534e-01]\n",
      " [  3.56470287e-01]\n",
      " [ -3.56888422e-03]\n",
      " [  9.67856147e-04]\n",
      " [ -2.38165140e-01]\n",
      " [ -1.48855364e+00]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "X, y, theta, mse, training_op = mini_batch_gradient_model()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Saving models\n",
    "saver = tf.train.Saver()\n",
    "# If you need to save only theta variables:\n",
    "# saver = tf.train.Saver({\"weights\": theta})\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):          \n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE = \", sess.run(mse, feed_dict={X: X_batch, y: y_batch}))\n",
    "            save_path = saver.save(sess, \"tmp/my_model.ckpt\")\n",
    "            \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"tmp/my_model_final.ckpt\")\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/my_model_final.ckpt\n",
      "[[ -5.29047012e-01]\n",
      " [  9.95532930e-01]\n",
      " [  9.72431973e-02]\n",
      " [ -3.68002534e-01]\n",
      " [  3.56470287e-01]\n",
      " [ -3.56888422e-03]\n",
      " [  9.67856147e-04]\n",
      " [ -2.38165140e-01]\n",
      " [ -1.48855364e+00]]\n"
     ]
    }
   ],
   "source": [
    "# _, _, theta, _, _ = mini_batch_gradient_model()\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "# Or you can just load the model from *.meta file\n",
    "# and add them to default graph\n",
    "saver = tf.train.import_meta_graph(\"tmp/my_model_final.ckpt.meta\")\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Don't need to init variables or train models\n",
    "    # because you will resotre model from the last checkpoint\n",
    "    saver.restore(sess, \"tmp/my_model_final.ckpt\")\n",
    "    theta = tf.get_default_graph().get_tensor_by_name(\"theta:0\")\n",
    "    best_theta = sess.run(theta)\n",
    "    print(best_theta)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Name Scopes & TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def nowstr():\n",
    "    return datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_gradient_model_with_name_scopes_and_stats():\n",
    "    root_logdir = \"tf_logs\"\n",
    "    logdir = \"{}/run-{}/\".format(root_logdir, nowstr())\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "    theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "\n",
    "    y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "    \n",
    "    with tf.name_scope(\"loss\") as scope:\n",
    "        error = y_pred - y\n",
    "        mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(mse)\n",
    "    \n",
    "    mse_summary = tf.summary.scalar(\"MSE\", mse)\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "    \n",
    "    return X, y, theta, mse_summary, training_op, file_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.98887968e-01]\n",
      " [  9.95532930e-01]\n",
      " [  9.72431973e-02]\n",
      " [ -3.68002534e-01]\n",
      " [  3.56470287e-01]\n",
      " [ -3.56888422e-03]\n",
      " [  9.67856147e-04]\n",
      " [ -2.38165140e-01]\n",
      " [ -1.48855364e+00]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "X, y, theta, mse_summary, training_op, file_writer = mini_batch_gradient_model_with_name_scopes_and_stats()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)\n",
    "\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_name_scope(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "\n",
    "        return tf.maximum(z, 0., name=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu_name_scope(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"tf_logs/relus-{}\".format(nowstr()), tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_variable_scope(X):\n",
    "    with tf.variable_scope(\"relu\", reuse=True):\n",
    "        # \"reuse=True\" above or scope.reuse_variables()\n",
    "        # Reuse mode cannot be reverted inside the block.\n",
    "        \n",
    "        # If threshold has not been defined earlier in \"relu\" variable scope, it will raise exception.\n",
    "        # Note that you can use this functionality when you only use tf.get_variable()\n",
    "        threshold = tf.get_variable(\"threshold\")\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "\n",
    "        return tf.maximum(z, threshold, name=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                               initializer=tf.constant_initializer(0.0))\n",
    "relus = [relu_variable_scope(X) for relu_index in range(5)]\n",
    "output = tf.add_n(relus, name=\"outout\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"tf_logs/relus-{}\".format(nowstr()), tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
